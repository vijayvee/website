<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-142161301-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-142161301-1');
  </script>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/Vijay_Profile.png">
  <title>Vijay Veerabadran</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <hr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Vijay Veerabadran</name>
              </p>
              <p>Hello there! My name is <font color="green">Vijay</font>, and I am a Ph.D. student at the UC San Diego. My research lies in the conjunction of primate vision and machine vision. I am working on developing the next generation of robust computer vision models by taking inspiration from computational principles that underlie primate vision. As a way of closing this loop of neuroscience to better machine learning, my work also involves the application state-of-the-art machine learning techniques to analyze neural data (i.e., machine learning to better neuroscience). </p>

              <p>I primarily work with my advisor, <a href="http://www.cogsci.ucsd.edu/~desa/">Dr. Virginia de Sa</a> at <a href="http://cogsci.ucsd.edu/">UCSD Cognitive Science</a>.
              </p>
              <p>
                Prior to starting my Ph.D., I spent a year working at Brown University with <a href="http://serre-lab.clps.brown.edu/">Dr. Thomas Serre</a>.
                In April 2017, I graduated with a bachelors degree in Computer Science and Engineering from <a href="http://www.ssn.edu.in/?page_id=124">SSN College of Engineering</a>, Chennai, India.
              </p>
              <p align=center>
                <a href="mailto:vveeraba@ucsd.edu">Email</a> &nbsp/&nbsp
                <a href="https://github.com/vijayvee/">Github</a> &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/16hUKPLtYdcdDXYoan6nuchwpEOPSCZ0L/view?usp=sharing">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=I6b38LoAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/vijayvee/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://twitter.com/vijayvee"> Twitter </a>
              </p>
            </td>

            <!-- <td width="33%">
              <img src="images/vijay.png">
            </td> -->
            <td>
              <table width="33%">
                <tr onmouseout="full_dp()" onmouseover="seg_dp()">
                  <td width="100%">
                  <div class="one">
                    <img src='images/vijay_full.png' width=200% style="position:absolute; top:-90px">
                      <div class="two" id='seg_img'><img src='images/vijay.png' width=200% style="position:absolute; top:-90px"></div>
                    </div>
                    <script type="text/javascript">
                      function seg_dp() {
                        document.getElementById('seg_img').style.opacity = "1";
                        document.getElementById('nonseg_img').style.opacity = "0";
                      }

                      function full_dp() {
                        document.getElementById('seg_img').style.opacity = "0";
                      }
                      full_dp()
                    </script>
                  </td>
                </tr>
              </table>
            </td>
          </tr>
        </table>
<!--
        </table>
      </td>
    </tr>  -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <hr>
              <heading>News</heading>
              <ul>
                <li> Sept 2020 - Joining as a Student Researcher at <a href="https://research.google/teams/brain/">Google Brain</a>, Mountain View, USA</li>
                <li> Summer 2020 - Joining as a Research Intern at <a href="https://research.google/teams/brain/">Google Brain</a>, Mountain View, USA</li>
                <li> Apr 2020 - Short paper on learned adversarial video compression accepted at the <a href="http://www.compression.cc/">Learned Image Compression (CLIC)</a> workshop at CVPR 2020</li>
                <li> Dec 2019 - Short paper introducing V1Net, a model of horizontal connections accepted at the <a href="https://www.svrhm2019.com/home"> SVRHM workshop</a> @ NeurIPS 2019</li>
                <li> Oct 2019 - My thesis work is the core of the project that was awarded a 2019 Kavli Symposium Inspired Proposal award for novel research at the intersection of AI and Neuroscience. </li>
                <li> Summer 2019 - Joining as a Research Intern at <a href="https://www.qualcomm.com/invention/artificial-intelligence/ai-research">Qualcomm AI Research</a> working with <a href="https://www.researchgate.net/profile/Reza_Pourreza">Reza Pourreza</a> and <a href="https://tacocohen.wordpress.com/">Taco Cohen</a>. </li>
                <li> Sept 2018 - Joining Dr. Virginia de Sa's group at UC San Diego as a Ph.D. student in Cognitive Science. </li>
                <li> Sept 2018 - Our work at the Serre Lab on inventing a novel recurrent cell has been accepted as a poster at <a href="https://nips.cc/Conferences/2018/Schedule?showEvent=11042">NeurIPS 2018.</a></li>
                <li> May 2018 - Single-handedly setup a brand new rodent recording/monitoring facility at the National Institutes of Health, Bethesda, in collaboration with the <a href="https://irp.nih.gov/pi/andrew-holmes">Holmes Lab</a>.</li>
                <li> Aug 2017 - Joined the Serre Lab as a Research Assistant working on Computer Vision.</li>
                <li> Jun 2017 - Completed B.E in Computer Science and Engineering at Anna University, Chennai.</li>
              </ul>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <hr>
              <heading>Research</heading>
              <p>
                My recent work is centered around the development of neurally inspired hierarchical and recurrent architectures with the help of computer vision and optogenetics data. I am interested in computationally reverse-engineering the visual cortex, and thereby utilize these models for relevant computer vision tasks to obtain brain-like robustness and sample efficiency.
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr>
            <td width="20%">
              <img src="images/videocomp.png" width="180"></td>
            </td>
            <td valign="middle" width="80%">
                <papertitle>Adversarial Distortion for Learned Video Compression
                </papertitle>
              </a>
              <br>
               <strong>Vijay Veerabadran</strong>, Reza Pourreza, Amirhossein Habibian, Taco. S. Cohen
              <br>
              <em>Learned Image Compression (CLIC) </em> 2020 (CVPRW 2020) <font color="red"><strong>(Poster Presentation)</strong> </font>
              <br>
              <a href="https://arxiv.org/pdf/2004.09508.pdf">arxiv</a>
<!--              <p>In this poster, we discuss the identification of early behavioral deficits in the SOD1-G85R mouse model for ALS. We also briefly discuss our automated behavioral monitoring system and its application to efficiently recording and analyzing activities of mice on a massively parallel scale.</p>-->
              <p>In this paper, we discuss the employment of adversarial distortion to improve the decoding perceptual quality of learned lossy video compression systems under extreme compression.</p>
            </td>
          </tr>

          <tr>
            <td width="20%">
              <img src="images/v1net.png" width="180"></td>
            </td>
            <td valign="middle" width="80%">
                <papertitle>V1Net: A computational model of long-range horizontal connections
                </papertitle>
              </a>
              <br>
               <strong>Vijay Veerabadran</strong>, Virginia de Sa
              <br>
              <em>Shared Visual Representations in Humans and Machines </em> (Workshop @ NeurIPS 2019) <font color="red"><strong>(Poster Presentation)</strong> </font>
              <br>
              <a href="https://drive.google.com/file/d/1w8o_yhIvosTSCrv0Y-VAu9GT1_zXSDIX/view">Paper link</a>
<!--              <p>In this poster, we discuss the identification of early behavioral deficits in the SOD1-G85R mouse model for ALS. We also briefly discuss our automated behavioral monitoring system and its application to efficiently recording and analyzing activities of mice on a massively parallel scale.</p>-->
              <p>In this paper, we introduce our model of recurrent nonlinear long-range horizontal connections and present initial results on their integration with Deep Convolutional Networks on the task of object boundary detection from natural images.</p>
            </td>
          </tr>

          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="20%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/cat_after.png'></div>
                <img src='images/cat_before.png'>
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }

                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>

            <td valign="middle" width="80%">
              <a href="https://arxiv.org/abs/1805.08315">
                <papertitle>Learning long-range spatial dependencies with horizontal gated-recurrent units
                </papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=cXZlAuQAAAAJ&hl=en/">Drew Linsley</a>,
              <a href="https://scholar.google.com/citations?user=xGxu6DoAAAAJ&hl=en">Junkyung Kim</a>,
              <strong>Vijay Veerabadran</strong>,
              Charlie Windolf,
              <a href="https://scholar.google.com/citations?user=kZlPW4wAAAAJ&hl=en">Thomas Serre</a>
              <br>
              <em>NeurIPS</em> 2018 <font color="red"><strong>(Poster Presentation)</strong></font>,
              <em>CCN</em> 2018 <font color="red"><strong>(Poster Presentation)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1805.08315">arxiv</a> /
              <a href="https://github.com/serre-lab/hgru_share">code</a>
              <p>Developed a novel recurrent cell inspired by long-range horizontal processing of spatial dependencies in the early visual cortex.</p>
            </td>
          </tr>
          <tr>
            <td width="20%">
              <img src="images/SfN.jpg"></td>
            </td>
            <td valign="middle" width="80%">
              <!-- <a href="https://arxiv.org/abs/1805.08315"> -->
                <papertitle>Automated continuous behavioral monitoring and traditional behavioral testing reveal early phenotypes in a novel SOD1-G85R knock-in mouse model of ALS
                </papertitle>
              </a>
              <br>
               *L. A. MADIGAN, J. PAGE, <strong>V. VEERABADRAN</strong>, T. SHARMA, J. DOMINOV, T. SERRE, R. H. BROWN, J. R. FALLON
              <br>
              <em>Society for Neuroscience</em> 2018 <font color="red"><strong>(Poster Presentation)</strong></font>,
              <br>
              <a href="https://www.abstractsonline.com/pp8/#!/4649/presentation/29641">Abstract</a>
              <p>In this poster, we discuss the identification of early behavioral deficits in the SOD1-G85R mouse model for ALS. We also briefly discuss our automated behavioral monitoring system and its application to efficiently recording and analyzing activities of mice on a massively parallel scale.</p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <hr>
              <heading>Projects</heading>
              <p> Listed below are a few of my recent research projects for which I have open-sourced my implementation. I have implemented all the below solutions using TensorFlow, my most comfortable framework for implementing neural architectures.
              </p>
            </td>
          </tr>
        </table>
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="20%"><img src="images/acbm.png" width=150px></td>
          <td width="80%" valign="center">
            <papertitle>Automated Continuous Behavioral Monitoring using Inception3D</papertitle>
            <br>
              <a href="https://github.com/vijayvee/behavior-recognition">
              Code /
              </a>
              <a href="images/output_behav.mp4">
                Demo
              </a>
              <p>
                I worked with Dr. Justin Fallon and Thomas Serre on an automated behavioral monitoring system to complement research in diagnosing neuromotor diseases through video analysis using deep learning.
            </p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="20%"><img src="images/videocap_full.png" width=150px></td>
          <td width="80%" valign="center">
            <papertitle>Automated Video Captioning - Undergraduate thesis</papertitle>
            <br>
              <a href="https://github.com/vijayvee/video-captioning">
              Code /
              </a>
              <a href="https://www.youtube.com/watch?v=tmLzgFdI7Xg">
                Demo
              </a>
              <p>
                I developed a sequence-to-sequence deep neural network to generate natural language captions describing input videos. This repository is one of the most popular repositories for video captioning on GitHub.
            </p>
          </td>
        </tr>
      </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <hr>
                <heading>Talks</heading>
              </td>
            </tr>
          </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="20%"><img src="images/neo_1.png" width=175px></td>
            <td width="80%" valign="center">
              <papertitle>Neocognitron: A neural network model for a mechanism of visual pattern recognition - Kunihiko Fukushima, Sei Miyake, Takayuki Ito
              </papertitle>
                <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwiHjJv8iePhAhVDoFsKHUb6AB0QFjAAegQIAhAC&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F71ea%2F46c9266f5104f79ea27fdfb4c5686677695a.pdf&usg=AOvVaw3ntheazy5f1TdCGOabuQwj">
                Slides
                </a>
                <p>
                I gave an introductory talk on the Neocognitron, the predecessor to Convolutional Neural Networks, at Sanjoy Dasgupta's seminar - CSE 254: Neurally Inspired Unsupervised Learning.
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="20%"><img src="images/gan.png" width=175px></td>
            <td width="80%" valign="center">
              <papertitle>Generative Adversarial Networks and Their Applications
              </papertitle>
                <a href="https://www.slideshare.net/Artifacia/generative-adversarial-networks-and-their-applications">
                  Slides
                </a>
                <p>
                In this talk that I delivered at Artifacia Inc., I presented an introduction to Generative Adversarial Networks and their applications to several cutting-edge computer vision problems.
              </p>

            </td>

          </tr>

        </table>
        <!-- <hr> -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
            <hr>
            <heading>Service</heading>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="20%"><img src="images/ICML.jpg" width=150px></td>
          <td width="80%" valign="center">
            <papertitle>Volunteering at <a href="https://icml.cc/Conferences/2019">ICML 2019</a>
            </papertitle>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="20%"><img src="images/CogSci.png" width=150px></td>
          <td width="80%" valign="center">
            <papertitle>Reviewer for <a href="https://cognitivesciencesociety.org/cogsci-2019/">CogSci 2019</a>
            </papertitle>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="20%"><img src="images/brain-logo.png" width=150px></td>
          <td width="80%" valign="center">
            <papertitle>Teaching assistant @ UCSD for <a href="http://thiscourse.com/ucsd/cogs118b/fa18/">COGS 118B: Intro to Machine Learning II (Unsupervised learning)</a> (Fall 2018, Fall 2019).
            </papertitle>
            <br>
            <papertitle>Teaching assistant @ UCSD for <a href="http://thiscourse.com/ucsd/cogs160bci/wi19/">COGS 189: EEG-based Brain-computer interfaces</a> (Winter 2019).
            </papertitle>
          </td>
        </tr>
      </table>
      </td>
      </tr>
      </table>
</body>

<center>Template overfitting on <a href="https://jonbarron.info/">https://jonbarron.info/</a></center>
</html>
